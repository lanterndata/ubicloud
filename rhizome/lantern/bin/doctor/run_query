#!/bin/env ruby
# frozen_string_literal: true

require "json"
require "yaml"
require_relative "../../../common/lib/util"
require_relative "../../lib/common"

$configure_hash = JSON.parse($stdin.read)
dbs = $configure_hash["dbs"]

def exec_sql(sql, user: "postgres", db: "postgres")
  r("docker compose -f #{$compose_file} exec -T postgresql psql -q -U #{user} -t --csv #{db}", stdin: sql).chomp.strip
end

def run_for_db(db)
  query = $configure_hash["query"]
  err = ""
  output = ""
  response_type = query["response_type"]
  name = query["name"]
  is_system = query["is_system"]
  fn_label = query["fn_label"]
  query_user = query["query_user"]
  sql = query["sql"]

  success = true
  begin
    if is_system && fn_label && SystemQueries.respond_to?(fn_label)
      res = SystemQueries.send(fn_label, db, query_user)
    elsif sql
      res = exec_sql(sql, db: db, user: query_user)
    else
      fail "BUG: non-system query without sql"
    end

    case response_type
    when "bool"
      if res != "f"
        success = false
      end
    when "rows"
      if res != ""
        success = false
      end
      output = res
    else
      fail "BUG: invalid response type (#{response_type}) on query #{name}"
    end
  rescue => e
    success = false
    err = e.message
  end

  [success, {db: db, result: output, err: err, success: success}]
end

class SystemQueries
  def self.get_jobs(db, query_user)
    jobs_table_exists = exec_sql(<<SQL)
      SELECT EXISTS (
       SELECT FROM pg_catalog.pg_class c
       JOIN   pg_catalog.pg_namespace n ON n.oid = c.relnamespace
       WHERE  n.nspname = '_lantern_extras_internal'
       AND    c.relname = 'embedding_generation_jobs'
       AND    c.relkind = 'r'
     );
SQL

    if jobs_table_exists == "f"
      return []
    end

    jobs = exec_sql("SELECT \"schema\", \"table\", src_column, dst_column, pk FROM _lantern_extras_internal.embedding_generation_jobs WHERE init_finished_at IS NOT NULL AND canceled_at IS NULL;")

    jobs.split("\n").map do |row|
      values = row.split(",")
      {schema: values[0], table: values[1], src_column: values[2], dst_column: values[3], pk: values[4]}
    end
  end

  def self.check_daemon_embedding_jobs(db, query_user)
    jobs = SystemQueries.get_jobs(db, query_user)

    if jobs.empty?
      return "f"
    end

    failed = jobs.any? do |job|
      res = exec_sql("SELECT (SELECT COUNT(*) FROM \"#{job[:schema]}\".\"#{job[:table]}\" WHERE \"#{job[:src_column]}\" IS NOT NULL AND \"#{job[:src_column]}\" != '' AND \"#{job[:src_column]}\" != 'Error: Summary failed (llm)' AND \"#{job[:dst_column]}\" IS NULL) > 2000", db: db, user: query_user)
      res == "t"
    end

    failed ? "t" : "f"
  end

  # return usage percent or 0 if device does not exist
  def self.usage_percent(device_name, subtract_tmp)
    total = (r "df | awk '$1 == \"#{device_name}\" {print $2}'").chomp.strip.to_i

    return 0 if total == 0 # the device does not exist

    fs_reserved_space = (total * 0.05).clamp(..5 * 1024 * 1024)
    effective_total_space = total - fs_reserved_space
    used = (r "df | awk '$1 == \"#{device_name}\" {print $3}'").chomp.strip.to_i
    pg_tmp = if subtract_tmp
      (r "(du -s #{$datadir}/data/base/pgsql_tmp/ 2>/dev/null || echo \"0\" )| awk '{print $1}'").chomp.strip.to_i
    else
      0
    end

    available = effective_total_space - (used - pg_tmp)

    100 - (available.to_f / effective_total_space * 100).to_i
  end

  def self.check_disk_space_usage(db, query_user)
    server_type = $configure_hash["server_type"]
    output = ""

    ["/dev/root", "/dev/sdb"].each {
      usage_percent = self.usage_percent _1, _1 == "/dev/sdb"
      if usage_percent > 90
        output += "#{server_type} server (#{_1}) - usage #{usage_percent}%\n"

        if _1 == "/dev/root"
          remove_dangling_images(db, query_user)
        end
      end
    }

    output.chomp
  end

  def self.check_embedding_source_whitespaces(db, query_user)
    jobs = SystemQueries.get_jobs(db, query_user)
    output = ""

    if jobs.empty?
      return output
    end

    jobs.each do |job|
      query = <<SQL
WITH whitespaces AS (
    SELECT
        id,
        unnest(regexp_matches("#{job[:src_column]}", '\s\s+', 'g')) AS whitespace_sequence
    FROM
        "#{job[:schema]}"."#{job[:table]}"
    WHERE
        "#{job[:src_column]}" IS NOT NULL
        AND "#{job[:src_column]}" != ''
        AND "#{job[:src_column]}" != 'Error: Summary failed (llm)'
    ORDER BY
        "#{job[:pk]}" DESC
    LIMIT 100000000
) SELECT
    SUM(LENGTH(whitespace_sequence) - 1) AS repeat_count
FROM
    whitespaces;
SQL
      whitespace_count = exec_sql(query, user: query_user, db: db).to_i

      if whitespace_count > 100000
        output += "#{job[:table]}.#{job[:src_column]} has #{whitespace_count} whitespace tokens which can be sanitized\n"
      end
    end

    output
  end

  def self.remove_dangling_images(_db, _query_user)
    r("sudo docker image prune -af")
    ""
  end

  def self.remove_dangling_index_files(_db, _query_user)
    r("sudo find /var/lib/lantern-data/data/ -name 'ldb-index*' -type f -mmin +240 -delete >/tmp/ldb-index-cleanup-logs 2>&1 && echo '' || cat /tmp/ldb-index-cleanup-logs").chomp.strip
  end
end

exit_code = 0

response = []
fn_label = $configure_hash["query"]["fn_label"]
is_system = $configure_hash["query"]["is_system"]

if is_system && fn_label && !SystemQueries.respond_to?(fn_label)
  # rhyzome is not synced yet
  warn "update_needed"
  exit(1)
end

dbs.each do |db|
  success, res = run_for_db(db)
  if !success
    exit_code = 1
  end
  response.push(res)
end

puts JSON.generate(response)

exit(exit_code)
